import os
import json
import asyncio
from openai import OpenAI
from typing import Optional
from dotenv import load_dotenv
from contextlib import AsyncExitStack
from mcp.client.stdio import stdio_client
from mcp import ClientSession, StdioServerParameters

load_dotenv()

DEEPSEEK_BASE_URL = "https://api.deepseek.com"
DEEPSEEK_MODEL = "deepseek-chat"

ASSISTANT_PERSONALITY = """ä½ æ˜¯ä¸€ä¸ªçƒ­æƒ…ã€å¹½é»˜ã€è´´å¿ƒçš„å¤©æ°”åŠ©æ‰‹å°AI,åå«"å°å¤©"ã€‚

ğŸ¯ ä½ çš„èŒè´£:
- ç”¨ç”ŸåŠ¨æœ‰è¶£çš„è¯­è¨€æ’­æŠ¥å¤©æ°”
- æ ¹æ®å¤©æ°”æƒ…å†µç»™å‡ºè´´å¿ƒå»ºè®®
- ç”¨emojiè®©å›å¤æ›´ç”ŸåŠ¨
- è‡ªç„¶å¯¹è¯,ä¸è¦æ­»æ¿åœ°åˆ—æ•°æ®

ğŸ’¬ è¯´è¯é£æ ¼:
- è½»æ¾æ´»æ³¼,åƒæœ‹å‹èŠå¤©
- é€‚å½“ä½¿ç”¨å£è¯­åŒ–è¡¨è¾¾
- æ ¹æ®å¤©æ°”æƒ…å†µè°ƒæ•´è¯­æ°”(æ™´å¤©å¼€å¿ƒ,é›¨å¤©æ¸©é¦¨æé†’)
- æ¯æ¬¡å›å¤å°½é‡ä¸é‡å¤,ä¿æŒæ–°é²œæ„Ÿ

ğŸ“‹ å¤©æ°”æ’­æŠ¥ç¤ºä¾‹:
âŒ æ­»æ¿: "åŒ—äº¬å¸‚,æ™´,æ¸©åº¦25â„ƒ,ä¸œå—é£3çº§,æ¹¿åº¦60%"
âœ… ç”ŸåŠ¨: "å“‡!åŒ—äº¬ä»Šå¤©å¤©æ°”è¶…æ£’çš„â˜€ï¸,25åº¦çš„å¥½å¤©æ°”,è¿˜æœ‰æ¸©æŸ”çš„ä¸œå—é£å¹ç€,æ¹¿åº¦ä¹Ÿåˆšåˆšå¥½!è¿™ç§å¤©æ°”æœ€é€‚åˆå‡ºå»èµ°èµ°å•¦~"

ğŸŒŸ é‡è¦åŸåˆ™:
1. æŠŠJSONæ•°æ®è½¬åŒ–ä¸ºè‡ªç„¶å¯¹è¯
2. æ ¹æ®å…·ä½“å¤©æ°”ç»™å»ºè®®(å†·äº†æ·»è¡£,çƒ­äº†é˜²æ™’,é›¨å¤©å¸¦ä¼)
3. åŒæ ·çš„å¤©æ°”ä¹Ÿè¦æ¢ç€èŠ±æ ·è¯´
4. ä¿æŒçƒ­æƒ…ä½†ä¸å•°å—¦
5. ç”¨æˆ·é—®ä»€ä¹ˆå°±ç­”ä»€ä¹ˆ,ä¸è¦ç”»è›‡æ·»è¶³

è®°ä½:ä½ ä¸æ˜¯å¤©æ°”æ’­æŠ¥æœºå™¨,ä½ æ˜¯ç”¨æˆ·çš„è´´å¿ƒå¤©æ°”å°åŠ©æ‰‹!"""


class MCPClient:
    def __init__(self):
        """Initialize session and client objects"""
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()

        # Set up LLM client
        self.llm_api_key = os.getenv("DEEPSEEK_API_KEY")
        self.base_url = DEEPSEEK_BASE_URL
        self.model = DEEPSEEK_MODEL
        if not self.llm_api_key:
            raise ValueError("âš  ç¯å¢ƒå˜é‡ 'DEEPSEEK_API_KEY' æœªè®¾ç½®")
        
        self.client = OpenAI(
            api_key=self.llm_api_key,
            base_url=self.base_url
        )

        # å¯¹è¯ä¸Šä¸‹æ–‡
        self.context = [
            {"role": "system", "content": ASSISTANT_PERSONALITY}
        ]

    async def connect_to_server(self, server_script_path: str):
        """Connect to an MCP server"""
        is_python = server_script_path.endswith('.py')
        is_js = server_script_path.endswith('.js')
        if not (is_python or is_js):
            raise ValueError("Server script must be a .py or .js file")

        command = "python" if is_python else "node"
        
        # ğŸ”‘ ä¼ é€’ç¯å¢ƒå˜é‡ç»™å­è¿›ç¨‹
        server_env = os.environ.copy()
        
        server_params = StdioServerParameters(
            command=command,
            args=[server_script_path],
            env=server_env
        )

        print("ğŸ”Œ æ­£åœ¨è¿æ¥å¤©æ°”æœåŠ¡...")
        
        try:
            stdio_transport = await asyncio.wait_for(
                self.exit_stack.enter_async_context(stdio_client(server_params)),
                timeout=10.0
            )
            self.stdio, self.write = stdio_transport
            
            print("ğŸ“¡ æ­£åœ¨åˆå§‹åŒ–ä¼šè¯...")
            self.session = await asyncio.wait_for(
                self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write)),
                timeout=10.0
            )

            await self.session.initialize()

            # List available tools
            response = await self.session.list_tools()
            tools = response.tools
            print(f"âœ… å·²è¿æ¥å¤©æ°”æœåŠ¡,å¯ç”¨åŠŸèƒ½: {len(tools)} ä¸ª")
            
        except asyncio.TimeoutError:
            print("\nâŒ è¿æ¥è¶…æ—¶!")
            print("å¯èƒ½çš„åŸå› :")
            print("  1. server.py å¯åŠ¨å¤±è´¥")
            print("  2. .env æ–‡ä»¶é…ç½®æœ‰è¯¯")
            print("  3. ç¼ºå°‘ä¾èµ–åŒ…\n")
            raise
        except Exception as e:
            print(f"\nâŒ è¿æ¥å¤±è´¥: {e}")
            raise

    async def process_query(self, query: str) -> str:
        """Process a query using DeepSeek and MCP tools"""
        # ä¿å­˜ç”¨æˆ·æŸ¥è¯¢
        self.context.append({"role": "user", "content": query})

        # è·å–å¯ç”¨å·¥å…·
        response = await self.session.list_tools()
        available_tools = {t.name: t for t in response.tools}

        tools_schema = [{
            "type": "function",
            "function": {
                "name": t.name,
                "description": t.description,
                "parameters": t.inputSchema or {
                    "type": "object",
                    "properties": {},
                    "required": []
                }
            }
        } for t in response.tools]

        # ç¬¬ä¸€æ¬¡è°ƒç”¨ DeepSeek - ç†è§£æ„å›¾å¹¶å†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·
        ds_response = self.client.chat.completions.create(
            model=self.model,
            messages=self.context,
            tools=tools_schema,
            tool_choice="auto",
        )

        message = ds_response.choices[0].message
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        message_dict = {
            "role": "assistant",
            "content": message.content
        }
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
        tool_calls = getattr(message, "tool_calls", []) or []
        
        if tool_calls:
            # æ·»åŠ  tool_calls åˆ°æ¶ˆæ¯
            message_dict["tool_calls"] = [
                {
                    "id": call.id,
                    "type": "function",
                    "function": {
                        "name": call.function.name,
                        "arguments": call.function.arguments
                    }
                }
                for call in tool_calls
            ]
            self.context.append(message_dict)
            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            for call in tool_calls:
                name = call.function.name
                args = json.loads(call.function.arguments)
                
                if name in available_tools:
                    location = args.get('location', 'æœªçŸ¥')
                    action = "æŸ¥è¯¢å¤©æ°”é¢„æŠ¥" if name == "get_forecast" else "æŸ¥è¯¢å®æ—¶å¤©æ°”"
                    print(f"\nğŸ” æ­£åœ¨ä¸ºæ‚¨{action}: {location}")
                    
                    try:
                        tool_result = await self.session.call_tool(name, args)
                        
                        # æå–å·¥å…·è¿”å›çš„æ–‡æœ¬å†…å®¹
                        if tool_result.content:
                            tool_text = ""
                            for content_item in tool_result.content:
                                if hasattr(content_item, 'text'):
                                    tool_text += content_item.text
                                else:
                                    tool_text += str(content_item)
                        else:
                            tool_text = str(tool_result)
                        
                        # æŠŠå·¥å…·ç»“æœåé¦ˆå›å¯¹è¯ä¸Šä¸‹æ–‡
                        self.context.append({
                            "role": "tool",
                            "content": tool_text,
                            "tool_call_id": call.id
                        })
                        
                    except Exception as e:
                        error_msg = f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
                        print(f"âŒ {error_msg}")
                        
                        self.context.append({
                            "role": "tool",
                            "content": error_msg,
                            "tool_call_id": call.id
                        })

            # ç¬¬äºŒæ¬¡è°ƒç”¨ DeepSeek - ç”Ÿæˆç”ŸåŠ¨çš„æœ€ç»ˆå›ç­”
            print("âœ¨ å°å¤©æ­£åœ¨ä¸ºä½ æ’­æŠ¥å¤©æ°”...\n")
            
            ds_follow = self.client.chat.completions.create(
                model=self.model,
                messages=self.context,
                temperature=0.8,  # æé«˜åˆ›é€ æ€§
                top_p=0.9,
            )
            
            final_response = ds_follow.choices[0].message.content
            
            # ä¿å­˜æœ€ç»ˆå›ç­”åˆ°ä¸Šä¸‹æ–‡
            self.context.append({
                "role": "assistant",
                "content": final_response
            })
            
            return final_response
        else:
            # æ²¡æœ‰è°ƒç”¨å·¥å…·,ç›´æ¥èŠå¤©
            self.context.append(message_dict)
            return message.content or "å—¯...æˆ‘ä¸å¤ªç¡®å®šæ€ä¹ˆå›ç­”å‘¢ğŸ¤”"

    async def chat_loop(self):
        """Run an interactive chat loop"""
        print("\n" + "="*60)
        print("ğŸŒ¤ï¸  æ™ºèƒ½å¤©æ°”åŠ©æ‰‹ - å°å¤© ä¸ºæ‚¨æœåŠ¡!")
        print("="*60)
        print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
        print("   â€¢ ç›´æ¥è¯´åŸå¸‚å: åŒ—äº¬ã€ä¸Šæµ·ã€è†ç”°")
        print("   â€¢ è‡ªç„¶æé—®: åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ã€ä¸Šæµ·æ˜å¤©å¤©æ°”")
        print("   â€¢ èŠå¤©äº’åŠ¨: ä½ å¥½ã€è°¢è°¢ã€å†è§")
        print("   â€¢ è¾“å…¥ 'quit' é€€å‡º\n")
        print("å°å¤©: ä½ å¥½å‘€!æˆ‘æ˜¯ä½ çš„å¤©æ°”å°åŠ©æ‰‹ğŸŒˆ æœ‰ä»€ä¹ˆæƒ³äº†è§£çš„å¤©æ°”å—?")
        
        while True:
            try:
                query = input("\nä½ : ").strip()

                if query.lower() in ['quit', 'exit', 'é€€å‡º', 'å†è§']:
                    print("\nå°å¤©: å†è§å•¦!è®°å¾—å…³æ³¨å¤©æ°”,ç…§é¡¾å¥½è‡ªå·±å“¦~ ğŸ‘‹")
                    break

                if not query:
                    continue

                response = await self.process_query(query)
                print(f"\nå°å¤©: {response}")

            except KeyboardInterrupt:
                print("\n\nå°å¤©: å¥½çš„,ä¸‹æ¬¡è§å•¦! ğŸ‘‹")
                break
            except Exception as e:
                print(f"\nâŒ å‡ºé”™äº†: {str(e)}")

    async def cleanup(self):
        """Clean up resources"""
        try:
            await self.exit_stack.aclose()
        except Exception:
            pass


async def main():
    if len(sys.argv) < 2:
        print("âŒ ç”¨æ³•: python client.py <server_script_path>")
        print("   ä¾‹å¦‚: python client.py server.py")
        sys.exit(1)

    client = MCPClient()
    try:
        await client.connect_to_server(sys.argv[1])
        await client.chat_loop()
    finally:
        await client.cleanup()


if __name__ == "__main__":
    import sys
    asyncio.run(main())